# FUTURE AI

![image](https://github.com/user-attachments/assets/27232d73-8e2e-4391-8bb9-cdf5f1296925)

هذا الـ fork من **FUTURE AI** (oTToDev) يتيح لك اختيار نموذج اللغة (LLM) الذي ترغب في استخدامه لكل طلب! حالياً، يمكنك استخدام نماذج OpenAI، Anthropic، Ollama، OpenRouter، Gemini، LMStudio، Mistral، xAI، HuggingFace، DeepSeek، أو Groq – وهو قابل للتوسيع بسهولة لإضافة أي نموذج آخر مدعوم من Vercel AI SDK! راجع التعليمات أدناه لتشغيله محلياً وتوسيعه لإضافة المزيد من النماذج.

## انضم إلى مجتمع oTToDev!

[https://thinktank.ottomator.ai](https://thinktank.ottomator.ai)

## الإضافات المطلوبة - لا تتردد في المساهمة!

- ✅ تكامل OpenRouter (@coleam00)
- ✅ تكامل Gemini (@jonathands)
- ✅ توليد النماذج تلقائيًا من ملفات Ollama المحملة (@yunatamos)
- ✅ تصفية النماذج حسب الموفر (@jasonm23)
- ✅ تحميل المشروع كملف ZIP (@fabwaseem)
- ✅ تحسينات في النموذج الرئيسي لـ FUTURE AI في `app\lib\.server\llm\prompts.ts` (@kofi-bhr)
- ✅ تكامل API DeepSeek (@zenith110)
- ✅ تكامل API Mistral (@ArulGandhi)
- ✅ تكامل API "Open AI Like" (@ZerxZ)
- ✅ مزامنة الملفات (مزامنة أحادية الاتجاه) إلى مجلد محلي (@muzafferkadir)
- ✅ حاوية التطبيق باستخدام Docker لتسهيل التثبيت (@aaronbolton)
- ✅ نشر المشاريع مباشرة على GitHub (@goncaloalves)
- ✅ واجهة مستخدم لتمكين إدخال مفاتيح API (@ali00209)
- ✅ تكامل xAI Grok Beta (@milutinke)
- ✅ تكامل LM Studio (@karrot0)
- ✅ تكامل HuggingFace (@ahsan3219)
- ✅ Terminal Bolt لعرض مخرجات أوامر LLM (@thecodacus)
- ✅ تدفق مخرجات التعليمات البرمجية (@thecodacus)
- ✅ إمكانية العودة إلى نسخة سابقة من الكود (@wonderwhy-er)
- ✅ تكامل Cohere (@hasanraiyan)
- ✅ طول الرموز الديناميكي للنماذج (@hasanraiyan)
- ✅ تحسينات على النصوص (@SujalXplores)
- ✅ التخزين المؤقت للنصوص (@SujalXplores)
- ✅ تحميل المشاريع المحلية في التطبيق (@wonderwhy-er)
- ✅ تكامل Together (@mouimet-infinisoft)
- ✅ واجهة موبايل (@qwikode)
- ✅ تحسينات على النصوص (@SujalXplores)
- ✅ إرفاق الصور بالنصوص (@atrokhym)
- ⬜ **أولوية عالية** - منع Bolt من كتابة الملفات بشكل متكرر (قفل الملفات والمقارنة)
- ⬜ **أولوية عالية** - إدارة أفضل للنصوص للنماذج الصغيرة (أحيانًا لا يبدأ نافذة الكود)
- ⬜ **أولوية عالية** - تنفيذ الوكلاء في الخلفية بدلاً من استدعاء نموذج واحد
- ⬜ نشر مباشر على Vercel/Netlify/منصات مشابهة
- ⬜ تمكين LLM من تخطيط المشروع في ملف MD لنتائج أفضل/شفافية
- ⬜ تكامل VSCode مع تأكيدات مشابهة لـ Git
- ⬜ تحميل مستندات لإدارة المعرفة - نماذج تصميم UI، قاعدة الكود كمرجع لأسلوب البرمجة، إلخ
- ⬜ الأوامر الصوتية
- ⬜ تكامل Azure Open AI API
- ⬜ تكامل Perplexity
- ⬜ تكامل Vertex AI

## FUTURE AI : تطوير ويب Full-Stack باستخدام الذكاء الاصطناعي في المتصفح

FUTURE AI هو وكيل تطوير ويب مدعوم بالذكاء الاصطناعي يتيح لك إنشاء وتشغيل وتحرير ونشر التطبيقات الكاملة من خلال متصفحك مباشرة – دون الحاجة إلى إعداد محلي. إذا كنت هنا لإنشاء وكيل تطوير ويب خاص بك باستخدام الكود المصدري لـ Bolt،

## ما الذي يجعل FUTURE AI مميزًا

Claude، v0، إلخ، مثيرة للإعجاب، لكنك لا تستطيع تثبيت الحزم أو تشغيل الخوادم أو تعديل الكود. هنا يأتي تفرد FUTURE AI:

- **Full-Stack في المتصفح** : يدمج FUTURE AI نماذج الذكاء الاصطناعي المتطورة مع بيئة تطوير في المتصفح مدعومة بـ **WebContainers** من StackBlitz. يتيح لك ذلك:
  - تثبيت وتشغيل الأدوات والمكتبات npm (مثل Vite، Next.js، إلخ)
  - تشغيل خوادم Node.js
  - التفاعل مع واجهات API من جهات خارجية
  - النشر في الإنتاج من خلال الدردشة
  - مشاركة عملك عبر عنوان URL

- **الذكاء الاصطناعي مع التحكم في البيئة** : على عكس بيئات التطوير التقليدية حيث لا يمكن للذكاء الاصطناعي سوى توليد الكود، يسمح لك FUTURE AI بنماذج الذكاء الاصطناعي بالتحكم الكامل في البيئة، بما في ذلك النظام الملفات، الخادم Node، مدير الحزم، الطرفية، ووحدة التحكم في المتصفح. وهذا يمكّن الوكلاء الذكاء الاصطناعي من إدارة دورة حياة التطبيق بالكامل من إنشائه إلى نشره.

سواء كنت مطورًا ذو خبرة أو قائد منتج أو مصممًا، يسمح لك FUTURE AI بإنشاء تطبيقات Full-Stack جاهزة للإنتاج بسهولة.

للمطورين المهتمين ببناء أدوات تطوير مدعومة بالذكاء الاصطناعي باستخدام WebContainers، راجع الكود المصدري لـ Bolt في هذا المستودع!

## الإعداد

### 1. قم بتثبيت Git و Node.js

- Git : [https://git-scm.com/downloads](https://git-scm.com/downloads)
- Node.js : [https://nodejs.org/en/download/](https://nodejs.org/en/download/)

### 2. استنساخ المستودع

```
git clone https://github.com/yassineelmiri/FUTURE_AI.git
```

### 3. إعادة تسمية `.env.example` إلى `.env.local` وأضف مفاتيح API الخاصة بك للنماذج.

### 4. قم بتشغيل التطبيق باستخدام Docker أو بدون Docker باتباع الخطوات المقدمة في README الأصلي.
